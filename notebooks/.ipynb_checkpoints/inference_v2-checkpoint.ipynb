{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from deeplab_test import DeepLabV3Plus\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 1280, 1280\n",
    "\n",
    "train_images = sorted(glob('resized_images/*'))\n",
    "train_masks = sorted(glob('resized_masks/*'))\n",
    "\n",
    "val_images = sorted(glob('validation_data/images/*'))\n",
    "val_masks = sorted(glob('validation_data/masks/*'))\n",
    "\n",
    "print(f'Found {len(train_images)} training images')\n",
    "print(f'Found {len(train_masks)} training masks')\n",
    "\n",
    "print(f'Found {len(val_images)} validation images')\n",
    "print(f'Found {len(val_masks)} validation masks')\n",
    "\n",
    "for i in range(len(train_masks)):\n",
    "    assert train_images[i].split('/')[-1].split('.')[0] == train_masks[i].split('/')[-1].split('.')[0]\n",
    "    \n",
    "for i in range(len(val_masks)):\n",
    "    assert val_images[i].split('/')[-1].split('.')[0] == val_masks[i].split('/')[-1].split('.')[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3Plus(H, W)\n",
    "model.load_weights('top_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_inputs(image, crop_height=H, crop_width=H, pad_value=0):\n",
    "    dims = tf.cast(tf.shape(image), dtype=tf.float32)\n",
    "    h_pad = tf.maximum(crop_height - dims[0], 0)\n",
    "    w_pad = tf.maximum(crop_width - dims[1], 0)\n",
    "    padded_image = tf.pad(image, paddings=[[0, h_pad], [0, w_pad], [0, 0]], constant_values=pad_value)\n",
    "    return padded_image, h_pad, w_pad\n",
    "\n",
    "def resize_preserve_aspect_ratio(image_tensor, max_side_dim):\n",
    "    img_h, img_w = image_tensor.shape.as_list()[:2]\n",
    "    min_dim = tf.maximum(img_h, img_w)\n",
    "    resize_ratio = max_side_dim / min_dim\n",
    "    new_h, new_w = resize_ratio * img_h, resize_ratio * img_w\n",
    "    resized_image_tensor = tf.image.resize(image_tensor, size=[new_h, new_w], method='bilinear')        \n",
    "    return resized_image_tensor\n",
    "\n",
    "def prepare_inputs(image_path, H=H, W=W, maintain_resolution=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    shape = image.shape.as_list()[:2]\n",
    "    if maintain_resolution:\n",
    "        disp_image = image.numpy().copy()\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    resized = False\n",
    "    if tf.maximum(shape[0], shape[1]) > H:\n",
    "        resized = True\n",
    "        image = resize_preserve_aspect_ratio(image, max_side_dim=H)\n",
    "    image, h_pad, w_pad = pad_inputs(image)\n",
    "    if not maintain_resolution:\n",
    "        disp_image = image.numpy().copy()\n",
    "    image = image[:, :, ::-1] - tf.constant([103.939, 116.779, 123.68])\n",
    "    return disp_image, tf.cast(image, dtype=tf.float32), np.int32(h_pad.numpy()), np.int32(w_pad.numpy()), resized\n",
    "\n",
    "def resize_mask(mask, size):\n",
    "    mask = tf.image.resize(mask[..., None], size, method='nearest')\n",
    "    return mask[..., 0]\n",
    "\n",
    "def pipeline(image_path, alpha=0.7, maintain_resolution=False):\n",
    "    disp_image, image, h_pad, w_pad, resized = prepare_inputs(image_path, maintain_resolution=maintain_resolution)\n",
    "    mask = model(image[None, ...])[0, ..., 0] > 0.5\n",
    "    mask = tf.cast(mask, dtype=tf.uint8)\n",
    "    b_h, b_w = (image.shape[:2] - tf.constant([h_pad, w_pad])).numpy()\n",
    "    disp_mask = mask[:b_h, :b_w].numpy()\n",
    "    if resized and maintain_resolution:\n",
    "        disp_mask = resize_mask(disp_mask, disp_image.shape[:2]).numpy()\n",
    "    else:\n",
    "        disp_image = disp_image[:b_h, :b_w]\n",
    "    overlay = disp_image.copy()\n",
    "    overlay[disp_mask == 0] = [255, 0, 0]\n",
    "    overlay[disp_mask == 1] = [0, 0, 255]\n",
    "    cv2.addWeighted(disp_image, alpha, overlay, 1-alpha, 0, overlay)\n",
    "    extracted_pixels = disp_image.copy()\n",
    "    extracted_pixels[disp_mask == 0] = [207, 207, 207]\n",
    "    return np.uint8(disp_image), np.uint8(np.concatenate([disp_mask[..., None]]*3, axis=-1)*255), np.uint8(overlay), np.uint8(extracted_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob('validation_data/images/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in tqdm_notebook(test_images[10:]):\n",
    "    output = pipeline(img, maintain_resolution=False)\n",
    "    result = np.concatenate(output, axis=1)\n",
    "    fname = img.split('/')[-1].split('.')[0] + '.png'\n",
    "    cv2.imwrite(f'_1024/{fname}', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
