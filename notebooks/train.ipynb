{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from deeplab import DeepLabV3Plus\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 512, 512\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4983 training images\n",
      "Found 4983 training masks\n",
      "Found 728 validation images\n",
      "Found 728 validation masks\n"
     ]
    }
   ],
   "source": [
    "train_images = sorted(glob('resized_images/*'))\n",
    "train_masks = sorted(glob('resized_masks/*'))\n",
    "\n",
    "val_images = sorted(glob('validation_data/images/*'))\n",
    "val_masks = sorted(glob('validation_data/masks/*'))\n",
    "\n",
    "print(f'Found {len(train_images)} training images')\n",
    "print(f'Found {len(train_masks)} training masks')\n",
    "\n",
    "print(f'Found {len(val_images)} validation images')\n",
    "print(f'Found {len(val_masks)} validation masks')\n",
    "\n",
    "for i in range(len(train_masks)):\n",
    "    assert train_images[i].split('/')[-1].split('.')[0] == train_masks[i].split('/')[-1].split('.')[0]\n",
    "    \n",
    "for i in range(len(val_masks)):\n",
    "    assert val_images[i].split('/')[-1].split('.')[0] == val_masks[i].split('/')[-1].split('.')[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scale(image, mask, min_scale=0.3, max_scale=1.5):\n",
    "    random_scale = tf.random.uniform(shape=[1], \n",
    "                                      minval=min_scale, \n",
    "                                      maxval=max_scale)\n",
    "    dims = tf.cast(tf.shape(image), dtype=tf.float32)\n",
    "    new_dims = tf.cast(random_scale * dims[:2], dtype=tf.int32)\n",
    "    scaled_image = tf.image.resize(image, size=new_dims, method='bilinear')\n",
    "    scaled_mask = tf.image.resize(mask, size=new_dims, method='nearest')    \n",
    "    return scaled_image, scaled_mask\n",
    "\n",
    "def pad_inputs(image, mask, crop_height=H, crop_width=H, ignore_value=255, pad_value=0):\n",
    "    dims = tf.cast(tf.shape(image), dtype=tf.float32)\n",
    "    h_pad = tf.maximum(1 + crop_height - dims[0], 0)\n",
    "    w_pad = tf.maximum(1 + crop_width - dims[1], 0)\n",
    "    padded_image = tf.pad(image, paddings=[[0, h_pad], [0, w_pad], [0, 0]], constant_values=pad_value)\n",
    "    padded_mask = tf.pad(mask, paddings=[[0, h_pad], [0, w_pad], [0, 0]], mode='CONSTANT', constant_values=ignore_value)    \n",
    "    return padded_image, padded_mask\n",
    "    \n",
    "def random_crop(image, mask, crop_height=512, crop_width=512):\n",
    "    image_dims = tf.shape(image)\n",
    "    offset_h = tf.random.uniform(shape=(1,), maxval=image_dims[0]-crop_height, dtype=tf.int32)[0]\n",
    "    offset_w = tf.random.uniform(shape=(1,), maxval=image_dims[1]-crop_height, dtype=tf.int32)[0]\n",
    "    \n",
    "    image = tf.image.crop_to_bounding_box(image, \n",
    "                                          offset_height=offset_h, \n",
    "                                          offset_width=offset_w, \n",
    "                                          target_height=crop_height, \n",
    "                                          target_width=crop_height)\n",
    "    mask = tf.image.crop_to_bounding_box(mask, \n",
    "                                          offset_height=offset_h, \n",
    "                                          offset_width=offset_w, \n",
    "                                          target_height=crop_height, \n",
    "                                          target_width=crop_height)\n",
    "    return image, mask\n",
    "\n",
    "def random_flip(image, mask):\n",
    "    flip = tf.random.uniform(shape=[1,], minval=0, maxval=2, dtype=tf.int32)[0]\n",
    "    image = tf.case([\n",
    "        (tf.greater(flip , 0), lambda : tf.image.flip_left_right(image))\n",
    "        ], default=lambda : image)\n",
    "    mask = tf.case([\n",
    "        (tf.greater(flip , 0), lambda : tf.image.flip_left_right(mask))\n",
    "        ], default=lambda : mask)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def load_image(image_path, mask=False):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    if mask:\n",
    "        img = tf.image.decode_image(img, channels=1)\n",
    "        img.set_shape([None, None, 1])\n",
    "    else:\n",
    "        img = tf.image.decode_image(img, channels=3)\n",
    "        img.set_shape([None, None, 3])        \n",
    "    return img\n",
    "\n",
    "@tf.function()\n",
    "def preprocess_inputs(image_path, mask_path):\n",
    "    with tf.device('/cpu:0'):\n",
    "        image = load_image(image_path)\n",
    "        mask = load_image(mask_path, mask=True)\n",
    "        mask = tf.cast(mask > 0, dtype=tf.uint8)\n",
    "\n",
    "        image, mask = random_scale(image, mask)\n",
    "        image, mask = pad_inputs(image, mask)\n",
    "        image, mask = random_crop(image, mask)\n",
    "        image, mask = random_flip(image, mask)\n",
    "        image = image[:, :, ::-1] - tf.constant([103.939, 116.779, 123.68])\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))\n",
    "train_dataset = train_dataset.shuffle(1024)\n",
    "train_dataset = train_dataset.map(map_func=preprocess_inputs, \n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks))\n",
    "val_dataset = val_dataset.map(map_func=preprocess_inputs, \n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "val_dataset= val_dataset.repeat()\n",
    "val_dataset= val_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Building DeepLabv3Plus Network ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mia/tensorflow2.0/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Output_Shape => (None, 512, 512, 1) ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0607 18:06:05.493605 140495535437632 distributed_training_utils.py:182] Your input callback is not one of the predefined Callbacks that supports DistributionStrategy. You might encounter an error if you access one of the model's attributes as part of the callback since these attributes are not set. You can access each of the individual distributed models using the `_grouped_model` attribute of your original model.\n",
      "W0607 18:06:05.494608 140495535437632 distributed_training_utils.py:182] Your input callback is not one of the predefined Callbacks that supports DistributionStrategy. You might encounter an error if you access one of the model's attributes as part of the callback since these attributes are not set. You can access each of the individual distributed models using the `_grouped_model` attribute of your original model.\n",
      "W0607 18:06:05.497222 140495535437632 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "W0607 18:06:12.073709 140445897156352 deprecation.py:323] From /home/mia/tensorflow2.0/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/mia/tensorflow2.0/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.3758 - accuracy: 0.7617 - dice_coef: 0.7628\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.55982, saving model to top_weights.h5\n",
      "207/207 [==============================] - 269s 1s/step - loss: 0.3748 - accuracy: 0.7622 - dice_coef: 0.7635 - val_loss: 1.1691 - val_accuracy: 0.4410 - val_dice_coef: 0.5598\n",
      "Epoch 2/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.2365 - accuracy: 0.8316 - dice_coef: 0.8610\n",
      "Epoch 00002: val_dice_coef improved from 0.55982 to 0.62465, saving model to top_weights.h5\n",
      "207/207 [==============================] - 226s 1s/step - loss: 0.2363 - accuracy: 0.8315 - dice_coef: 0.8609 - val_loss: 0.8670 - val_accuracy: 0.5571 - val_dice_coef: 0.6247\n",
      "Epoch 3/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1986 - accuracy: 0.8433 - dice_coef: 0.8867\n",
      "Epoch 00003: val_dice_coef improved from 0.62465 to 0.64411, saving model to top_weights.h5\n",
      "207/207 [==============================] - 227s 1s/step - loss: 0.1987 - accuracy: 0.8433 - dice_coef: 0.8865 - val_loss: 0.8196 - val_accuracy: 0.5982 - val_dice_coef: 0.6441\n",
      "Epoch 4/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1857 - accuracy: 0.8481 - dice_coef: 0.8904\n",
      "Epoch 00004: val_dice_coef improved from 0.64411 to 0.73071, saving model to top_weights.h5\n",
      "207/207 [==============================] - 227s 1s/step - loss: 0.1856 - accuracy: 0.8482 - dice_coef: 0.8906 - val_loss: 0.5591 - val_accuracy: 0.6971 - val_dice_coef: 0.7307\n",
      "Epoch 5/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1715 - accuracy: 0.8491 - dice_coef: 0.8982\n",
      "Epoch 00005: val_dice_coef improved from 0.73071 to 0.78483, saving model to top_weights.h5\n",
      "207/207 [==============================] - 227s 1s/step - loss: 0.1716 - accuracy: 0.8491 - dice_coef: 0.8983 - val_loss: 0.4323 - val_accuracy: 0.7518 - val_dice_coef: 0.7848\n",
      "Epoch 6/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1610 - accuracy: 0.8548 - dice_coef: 0.9061\n",
      "Epoch 00006: val_dice_coef did not improve from 0.78483\n",
      "207/207 [==============================] - 226s 1s/step - loss: 0.1610 - accuracy: 0.8546 - dice_coef: 0.9061 - val_loss: 0.4763 - val_accuracy: 0.7462 - val_dice_coef: 0.7702\n",
      "Epoch 7/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1534 - accuracy: 0.8634 - dice_coef: 0.9110\n",
      "Epoch 00007: val_dice_coef improved from 0.78483 to 0.80059, saving model to top_weights.h5\n",
      "207/207 [==============================] - 227s 1s/step - loss: 0.1531 - accuracy: 0.8635 - dice_coef: 0.9112 - val_loss: 0.4273 - val_accuracy: 0.7683 - val_dice_coef: 0.8006\n",
      "Epoch 8/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1518 - accuracy: 0.8656 - dice_coef: 0.9131\n",
      "Epoch 00008: val_dice_coef improved from 0.80059 to 0.80212, saving model to top_weights.h5\n",
      "207/207 [==============================] - 227s 1s/step - loss: 0.1514 - accuracy: 0.8657 - dice_coef: 0.9134 - val_loss: 0.4151 - val_accuracy: 0.7719 - val_dice_coef: 0.8021\n",
      "Epoch 9/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1435 - accuracy: 0.8634 - dice_coef: 0.9169\n",
      "Epoch 00009: val_dice_coef improved from 0.80212 to 0.81243, saving model to top_weights.h5\n",
      "207/207 [==============================] - 228s 1s/step - loss: 0.1434 - accuracy: 0.8633 - dice_coef: 0.9169 - val_loss: 0.4190 - val_accuracy: 0.7864 - val_dice_coef: 0.8124\n",
      "Epoch 10/10\n",
      "206/207 [============================>.] - ETA: 1s - loss: 0.1388 - accuracy: 0.8626 - dice_coef: 0.9196\n",
      "Epoch 00010: val_dice_coef did not improve from 0.81243\n",
      "207/207 [==============================] - 225s 1s/step - loss: 0.1391 - accuracy: 0.8622 - dice_coef: 0.9194 - val_loss: 0.4371 - val_accuracy: 0.7722 - val_dice_coef: 0.7995\n"
     ]
    }
   ],
   "source": [
    "@tf.function()\n",
    "def dice_coef(y_true, y_pred):\n",
    "    mask =  tf.equal(y_true, 255)\n",
    "    mask = tf.logical_not(mask)\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "@tf.function()\n",
    "def loss(y_true, y_pred):\n",
    "    mask =  tf.equal(y_true, 255)\n",
    "    mask = tf.logical_not(mask)\n",
    "    y_true = tf.boolean_mask(y_true, mask)\n",
    "    y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    return tf.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = DeepLabV3Plus(H, W)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.momentum = 0.9997\n",
    "            layer.epsilon = 1e-5\n",
    "        elif isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(1e-4)\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "                  metrics=['accuracy', dice_coef])\n",
    "\n",
    "\n",
    "tb = TensorBoard(log_dir='logs', write_graph=True, update_freq='batch')\n",
    "mc = ModelCheckpoint(filepath='top_weights.h5',\n",
    "                     monitor='val_dice_coef', \n",
    "                     mode='max',\n",
    "                     save_best_only='True',\n",
    "                     save_weights_only='True', verbose=1)\n",
    "callbacks = [mc, tb]\n",
    "\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          steps_per_epoch=len(train_images) // batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=len(val_images) // batch_size,\n",
    "          callbacks=callbacks)\n",
    "model.save_weights('last_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
